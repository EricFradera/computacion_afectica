# Consideraciones éticas

El monitoreo constante que la computación afectiva crea muchas preguntas sobre cómo serán utilizados los datos de usuarios. Es una incógnita de qué forma se materializará la computación afectiva en el fututo, pero sí que hoy en día ya se pueden hacer preguntas sobre como afectaran a los usuarios la implementación de estas tecnologías en nuestro día a día.

La detección de mentiras es un campo que se ha investigador por décadas. Los polígrafos nunca han sido instrumentos precisos, pero si que generan una realidad incomoda donde se arrebata al usuario la capacidad de mentir, ya que la maquina sabrá cuando esta miente o no. Las implicaciones de un instrumento que detecta mentiras o emociones ponen en peligro la libertad de expresión al poner en peligro a pensamientos disidentes de una realidad política o económica. En una sociedad más autoritaria se podría utilizar estas tecnologías para descubrir aquellas personas que no creen en un régimen, eliminando las diferencias de pensamiento dentro de una sociedad.

Estas últimas conjeturas ya han sido usadas en países como Iraq o países del “primer mundo” como Estados Unidos. Aunque actualmente estos mecanismos se utilizan principalmente en prisiones o con presuntos delincuentes en juicios, sí que crea la incógnita de si estas tecnologías se utilizaran en los ciudadanos.

El control de masas ya es un aspecto altamente controvertido, pero que a través de la computación afectiva tecnologías como la detección facial, le detección de emociones vía texto se automatiza y se masifica el control social del contenido posteado online y incluso el del mundo real a través de cámaras o micrófonos.

Los dispositivos inteligentes forman parte del día a día de los usuarios y son herramientas más que capaces de detectar emociones e inferir a través de los datos obtenidos pensamientos políticos o ideológicos.

La manipulación emocional es otro tipo de inquietud que se genera derivado de la computación afectiva. Conociendo las emociones de los usuarios frente algún tipo de contenido no es difícil de pensar como se pueden utilizar estas para modificar su forma de pensamiento. Durante años se ha analizado los rabbit holes de la ultraderecha que radicalizan a jóvenes poco a poco hasta llevarlos a visiones políticas extremistas normalmente a través de un discurso basada en los miedos y inquietudes de la población. El conocimiento y adaptación de contenido de los usuarios es peligrosa por la capacidad que tienen de doblegar poco a poco el sentido común.

Viendo el panorama actual podemos observar cómo algunas redes sociales como Facebook han utilizado la ira para mejorar el *engagement* de sus usuarios. Se analizo y se observo que las publicaciones que generaban ira hacia algún grupo creaban mayor interacción ya que se reacciona, se compartía y se comentaba mucho más que en publicaciones normales. Esto ha hecho que las fakeNews que tienen como objetivo de repartir información falsa, sean extremadamente populares dentro de esta plataforma. A causa de esto Facebook se ha convertido en una de las mayores fuentes de información difamatoria.

Esta manipulación emocional no tiene que venir solo desde puntos de vista políticos sino económicos. Ya es práctica común la recomendación de anuncios en base a gustos personales de plataformas como Google ads o algoritmos de recomendación de contenido como tik tok. Hoy en día estos algoritmos ya se utilizan para “comprar usuarios” solo mediante el contenido que estos buscan. Tener un input emocional genera situaciones incomodas en las que los anuncios se posicionan en momentos de debilidad donde el usuario tiene la guardia mas baja y tiene mayor probabilidad de hacer clic.

Otro elemento en riesgo es la generación de contenido en base a estudios de mercado. A través del análisis de las emociones de los usuarios en contenido como películas o música existe el peligro de reducción de la variedad artística al solo invertir en base a aquellas películas que generen mayor *engagement*, reduciendo la variedad y creando grandes carencias artísticas. 

 

Este pequeño análisis sobre los peligros éticos que la computación afectiva puede traer en contrasta a tendencias actuales no es una lista exhaustiva, sino que plante algunos de los grandes peligros que podrían llegar a aparecer dentro de una transición tecnología hacia estas líneas de diseño. Aunque aún es pronto para saber qué dirección se tomara es de urgente importancia un análisis riguroso de las tendencias dentro del campo para establecer un marco ético que permita a los desarrolladores crear productos innovadores al mismo tiempo que respetan a los usuarios.